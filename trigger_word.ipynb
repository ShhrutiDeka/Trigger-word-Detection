{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trigger_word.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOGea3+NyhSfViF0n6Hrs2Y"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"FCMWa1NUClQo"},"source":["\r\n","import pandas as pd\r\n","import os\r\n","import matplotlib.pyplot as plt\r\n","from scipy.io import wavfile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxtZ5DRgCz1d"},"source":["#use folders of audio image data\r\n","\r\n","#Training data\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","\r\n","image_datagen = ImageDataGenerator(rescale=1./255)\r\n","\r\n","image_generator_train = image_datagen.flow_from_directory(\r\n","    '/content/drive/MyDrive/phoebe/phoebe_chunk_spec/',\r\n","    target_size=(150, 150),\r\n","    batch_size=4,\r\n","    class_mode='binary')\r\n","\r\n","#Validation data\r\n","image_generator_val = image_datagen.flow_from_directory(\r\n","    '/content/drive/MyDrive/phoebe/phoebe_chunk_val_spec/',\r\n","    target_size=(150, 150),\r\n","    batch_size=4,\r\n","    class_mode='binary')\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5p07t--DoVb"},"source":["import tensorflow as tf\r\n","\r\n","model = tf.keras.models.Sequential([\r\n","    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\r\n","    tf.keras.layers.Conv2D(16, kernel_size = (3,3), activation='relu', input_shape=(150, 150, 3)),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2), \r\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","    # Flatten the results to feed into a DNN\r\n","    tf.keras.layers.Flatten(), \r\n","    # 512 neuron hidden layer\r\n","    tf.keras.layers.Dense(512, activation='relu'), \r\n","    # Only 1 output neuron.\r\n","    tf.keras.layers.Dense(1, activation='sigmoid')  \r\n","])\r\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BKBx821UDw0q"},"source":["from tensorflow.keras.optimizers import RMSprop\r\n","\r\n","model.compile(optimizer=RMSprop(lr=0.001),\r\n","              loss='binary_crossentropy',\r\n","              metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oeDurUs0D4x2"},"source":["history = model.fit(image_generator_train,\r\n","                    validation_data = (image_generator),\r\n","                    steps_per_epoch=10,\r\n","                    epochs=100,\r\n","                    verbose=2)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Ob0zlgSEBrF"},"source":["save model"]},{"cell_type":"code","metadata":{"id":"RBJTWNWUED7n"},"source":["model.save('/content/drive/MyDrive/phoebe/trigger_word_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l7pUdTwuES5a"},"source":["Load model and test it on an audio image, transformed into an array of numbers"]},{"cell_type":"code","metadata":{"id":"pp7C9jzGEOxq"},"source":["import tensorflow as tf\r\n","new_model = tf.keras.models.load_model('/content/drive/MyDrive/phoebe/trigger_word_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nE5fd059EbtF"},"source":["#use 1 validation audio for testing\r\n","from keras.preprocessing import image\r\n","path = '/content/drive/MyDrive/phoebe/phoebe_chunk_val_spec/class1/audio00.png'\r\n","img=image.load_img(path, target_size=(150, 150))\r\n","\r\n","x=image.img_to_array(img)\r\n","x=np.expand_dims(x, axis=0)\r\n","#images = np.vstack([x])\r\n","\r\n","print(new_model.predict(x))"],"execution_count":null,"outputs":[]}]}
