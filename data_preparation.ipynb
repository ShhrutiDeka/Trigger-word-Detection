{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preparation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zNeapgQobGc"
      },
      "source": [
        "#for phoebe to recognize her name if spoken ('always on' mode)\r\n",
        "!pip install pydub\r\n",
        "\r\n",
        "from pydub import AudioSegment\r\n",
        "\r\n",
        "from pydub.silence import split_on_silence\r\n",
        "import os\r\n",
        "\r\n",
        "!pip install SpeechRecognition\r\n",
        "!pip install pipwin\r\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\r\n",
        "#!pip install PyAudio\r\n",
        "!pipwin install pyaudio\r\n",
        "\r\n",
        "import speech_recognition as s\r\n",
        "from scipy.io import wavfile\r\n",
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7noUgcPredp"
      },
      "source": [
        "#concatenate background sounds in wav format\r\n",
        "\r\n",
        "fnames =[\"cafe.wav\", \"newspaper.wav\", \"Indoor-Restaurant.wav\"]\r\n",
        "sound = sum([AudioSegment.from_wav(f) for f in fnames])\r\n",
        "\r\n",
        "sound.export('mybackground.wav', format=\"wav\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy8gUCTHrtSY"
      },
      "source": [
        "#overlay audio with background\r\n",
        "\r\n",
        "sound1 = AudioSegment.from_file(\"Voice-003.wav\")\r\n",
        "sound2 = AudioSegment.from_file(\"mybackground.wav\")\r\n",
        "\r\n",
        "combined = sound1.overlay(sound2)\r\n",
        "\r\n",
        "combined.export(\"training.wav\", format='wav')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRYEo33Cr-wW"
      },
      "source": [
        "#split the stream into different inputs (rows)\r\n",
        "\r\n",
        "def split(filepath):\r\n",
        "    sound = AudioSegment.from_wav(filepath)\r\n",
        "    dBFS = sound.dBFS\r\n",
        "    chunks = split_on_silence(sound, \r\n",
        "        min_silence_len = 80,\r\n",
        "        silence_thresh = dBFS-16,\r\n",
        "        keep_silence = 250)\r\n",
        "    return chunks\r\n",
        "    \r\n",
        "    \r\n",
        "filepath = \"training.wav\"\r\n",
        "chunks = split(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkh5vX5CsTmI"
      },
      "source": [
        "#save the split files\r\n",
        "for i, chunk in enumerate(chunks):\r\n",
        "    chunk.export(os.path.join(\"phoebe training chunks/\", \"audio\" + \"{0}.wav\".format(\"%02d\" % i)), format=\"wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFfuFMX8shkQ"
      },
      "source": [
        "#see how the audios are recognised - speech-to-text\r\n",
        "\r\n",
        "r = s.Recognizer()\r\n",
        "l = []\r\n",
        "for f in os.listdir('phoebe training chunks/'):\r\n",
        "    with s.AudioFile('phoebe training chunks/'+f) as source:\r\n",
        "        audio = r.record(source)\r\n",
        "        try:\r\n",
        "            l.extend([r.recognize_google(audio)])\r\n",
        "        except:\r\n",
        "            l.extend([0]) #take 0 if can't recognise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So4etcBhtW8v"
      },
      "source": [
        "print(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0AwJbpxtmCR"
      },
      "source": [
        "\r\n",
        "#create images from .wav file (already defined audios)\r\n",
        "\r\n",
        "for f in os.listdir('phoebe training chunks/') :\r\n",
        "  \r\n",
        "  samplingFrequency, signalData = wavfile.read('phoebe training chunks/'+f)\r\n",
        "\r\n",
        "  plt.title('Spectrogram')\r\n",
        "\r\n",
        "  plt.specgram(signalData[:,0],Fs=samplingFrequency,NFFT=512)\r\n",
        "\r\n",
        "  plt.xlabel('Time')\r\n",
        "\r\n",
        "  plt.ylabel('Frequency')\r\n",
        "\r\n",
        "  plt.savefig('phoebe_training_spec/'+ f.split('.')[0]+'.png') #save files into one folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqwFCc9uvUQF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}